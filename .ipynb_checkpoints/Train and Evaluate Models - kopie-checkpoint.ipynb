{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from MetaMF import *\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize random seeds and select GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1) # set random seed for cpu\n",
    "torch.cuda.manual_seed(1) # set random seed for current gpu\n",
    "torch.cuda.manual_seed_all(1) # set random seed for all gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available? False\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    use_cuda = True\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    use_cuda = False\n",
    "print(\"CUDA available? \" + str(use_cuda))\n",
    "if use_cuda:\n",
    "    print(\"Current device: %d\" % torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    trainset = pd.read_csv(path + \".train.rating\", sep = ',', header=None).to_records(index=False).tolist()\n",
    "    valset = pd.read_csv(path + \".valid.rating\", sep = ',', header=None).to_records(index=False).tolist()\n",
    "    testset = pd.read_csv(path + \".test.rating\", sep = ',', header=None).to_records(index=False).tolist()\n",
    "    \n",
    "    return trainset, valset, testset\n",
    "\n",
    "def read_usergroups(path):\n",
    "    low_users = pd.read_csv(path + \"_low.userlist\", header=None, squeeze=True).values.tolist()\n",
    "    med_users = pd.read_csv(path + \"_med.userlist\", header=None, squeeze=True).values.tolist()\n",
    "    high_users = pd.read_csv(path + \"_high.userlist\", header=None, squeeze=True).values.tolist()\n",
    "    \n",
    "    return low_users, med_users, high_users\n",
    "\n",
    "def read_useranditemlist(path):\n",
    "    userlist = pd.read_csv(path + \".userlist\", header=None, squeeze=True).values.tolist()\n",
    "    itemlist = pd.read_csv(path + \".itemlist\", header=None, squeeze=True).values.tolist()\n",
    "    \n",
    "    return userlist, itemlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchtoinput(batch, use_cuda):\n",
    "    users = []\n",
    "    items = []\n",
    "    ratings = []\n",
    "    for example in batch:\n",
    "        users.append(example[0])\n",
    "        items.append(example[1])\n",
    "        ratings.append(example[2])\n",
    "    users = torch.tensor(users, dtype=torch.int64)\n",
    "    items = torch.tensor(items, dtype=torch.int64)\n",
    "    ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "    if use_cuda:\n",
    "        users = users.cuda()\n",
    "        items = items.cuda()\n",
    "        ratings = ratings.cuda()\n",
    "    return users, items, ratings\n",
    "\n",
    "def getbatches(traindata, batch_size, use_cuda, shuffle):\n",
    "    dataset = traindata.copy()\n",
    "    if shuffle:\n",
    "        random.shuffle(dataset)\n",
    "    for batch_i in range(0,int(np.ceil(len(dataset)/batch_size))):\n",
    "        start_i = batch_i*batch_size\n",
    "        batch = dataset[start_i:start_i+batch_size]\n",
    "        yield batchtoinput(batch, use_cuda)\n",
    "        \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "def get_eval(ratlist, predlist):\n",
    "    mae = np.mean(np.abs(ratlist-predlist))\n",
    "    mse = np.mean(np.square(ratlist-predlist))       \n",
    "    return  mae, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Functions\n",
    "## Sampling Procedure\n",
    "Here, we implement a sampling procedure to simulate a privacy budget $\\beta$. In detail, we randomly select a fraction of $\\beta$ of each user's rating data to be shared with the model. Thus, a user holds back a fraction of $1-\\beta$ of her data and provides only a fraction of $\\beta$ of her data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_procedure(dataset, beta):\n",
    "    dataframe = pd.DataFrame(dataset, columns=[\"user_id\", \"item_id\", \"rating\"])\n",
    "    n_samples = np.ceil(dataframe.groupby(\"user_id\").size() * (beta)).astype(int)\n",
    "    new_dataset = []\n",
    "    for uid, group in dataframe.groupby(\"user_id\"):\n",
    "        new_dataset.extend(group.sample(n=n_samples.loc[uid]).to_records(index=False).tolist())\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments\n",
    "This method trains and tests MetaMF and NoMetaMF under ten different privacy budgets (i.e., $\\beta \\in \\{1.0, 0.9, \\dots, 0.1\\}$). For NoMetaMF, meta learning the parameters of the rating prediction model can be disabled. Furthermore, we evaluate the model's accuracy in terms of the mean squared error and the mean absolute error on both, all users in the dataset and on our three user groups (i.e., $Low, Med, High$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(path, traindata, valdata, testdata, userlist, itemlist, low, med, high, hyperparameters, betas=None, disable_meta_learning=False, save=False):\n",
    "    # default choice of privacy budget beta\n",
    "    if betas is None:\n",
    "        betas = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "        \n",
    "    if os.path.exists(path + \"/results.csv\"):\n",
    "        results_df = pd.read_csv(path + \"/results.csv\")\n",
    "    else:\n",
    "        results_df = pd.DataFrame()\n",
    "        \n",
    "    for beta in betas:\n",
    "        results_dict = {\"beta\": beta}\n",
    "        model_name = \"beta_\" + str(int(beta*100)) + \"p\"  \n",
    "        print(\"==========================\")\n",
    "        print(model_name)\n",
    "        print(\"==========================\")\n",
    "        starttime = dt.now()\n",
    "        \n",
    "        # sample a fraction of beta of each user's data to simulate privacy budget beta\n",
    "        R_train_beta = sampling_procedure(traindata, beta)\n",
    "        \n",
    "        train_loss, validation_loss = [], []\n",
    "        net = MetaMF(len(userlist), len(itemlist))\n",
    "        \n",
    "        # disable meta learning for NoMetaMF\n",
    "        if disable_meta_learning:\n",
    "            net.disable_meta_learning()\n",
    "        \n",
    "        # initialize parameters of neural network\n",
    "        net.apply(weights_init)\n",
    "        if use_cuda:\n",
    "            net.cuda()\n",
    "        \n",
    "        # model training\n",
    "        optimizer = optim.Adam(net.parameters(), lr=hyperparameters[\"lr\"], weight_decay=hyperparameters[\"lambda\"])\n",
    "        batch_size = hyperparameters[\"batch_size\"]\n",
    "        n_epochs = hyperparameters[\"n_epochs\"]\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            net.train()\n",
    "            error = 0\n",
    "            num = 0\n",
    "            for k, (users, items, ratings) in enumerate(getbatches(R_train_beta, batch_size, use_cuda, True)):\n",
    "                optimizer.zero_grad()\n",
    "                pred = net(users, items)\n",
    "\n",
    "                loss = net.loss(pred, ratings)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(net.parameters(), 5)\n",
    "                optimizer.step()\n",
    "                error += loss.detach().cpu().numpy()*len(users)\n",
    "                num += len(users)\n",
    "            train_loss.append(error/num)\n",
    "            \n",
    "            # evaluate training error\n",
    "            net.eval()\n",
    "            groundtruth, estimation = [], []\n",
    "            for users, items, ratings in getbatches(valdata, batch_size, use_cuda, False):\n",
    "                predictions = net(users, items)\n",
    "                estimation.extend(predictions.tolist())\n",
    "                groundtruth.extend(ratings.tolist())\n",
    "            mae, mse = get_eval(np.array(groundtruth), np.array(estimation))\n",
    "            validation_loss.append(mse)\n",
    "            \n",
    "            print('Epoch {}/{} - Training Loss: {:.3f}, Validation Loss: {:.3f}, Time Elapsed: {}'.format(epoch+1, n_epochs, error/num, mse, dt.now()-starttime))\n",
    "            \n",
    "            if epoch+1 == n_epochs:\n",
    "                if save:\n",
    "                    torch.save(net, path + \"/\" + model_name + '.model')\n",
    "                    print(\"Saved Model to \" + path)\n",
    "                \n",
    "                results_dict[\"train_mse_all\"] = error / num\n",
    "                results_dict[\"val_mse_all\"] = mse\n",
    "        \n",
    "        # plot training and validation error to observe convergence\n",
    "        net.eval()\n",
    "        plt.figure()\n",
    "        plt.plot(range(n_epochs), train_loss, label=\"Train\")\n",
    "        plt.plot(range(n_epochs), validation_loss, label=\"Val\")\n",
    "        plt.legend()\n",
    "        plt.ylabel(\"MSE\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # evaluate test error on both, all users in the dataset and on our three user groups\n",
    "        groundtruth, estimation = [], []\n",
    "        group_groundtruth = defaultdict(list)\n",
    "        group_estimation = defaultdict(list)\n",
    "        for users, items, ratings in getbatches(testdata, batch_size, use_cuda, False):\n",
    "            predictions = net(users, items)\n",
    "            estimation.extend(predictions.tolist())\n",
    "            groundtruth.extend(ratings.tolist())\n",
    "            \n",
    "            for uid, iid, r, p in zip(users.cpu().numpy(), items.cpu().numpy(), ratings.cpu().numpy(), predictions.detach().cpu().numpy()):\n",
    "                if uid in low:\n",
    "                    group_groundtruth[\"low\"].append(r)\n",
    "                    group_estimation[\"low\"].append(p)\n",
    "                elif uid in med:\n",
    "                    group_groundtruth[\"med\"].append(r)\n",
    "                    group_estimation[\"med\"].append(p)\n",
    "                elif uid in high:\n",
    "                    group_groundtruth[\"high\"].append(r)\n",
    "                    group_estimation[\"high\"].append(p)\n",
    "        \n",
    "        test_mae, test_mse = get_eval(np.array(groundtruth), np.array(estimation))\n",
    "        low_mae, low_mse = get_eval(np.array(group_groundtruth[\"low\"]), np.array(group_estimation[\"low\"]))\n",
    "        med_mae, med_mse = get_eval(np.array(group_groundtruth[\"med\"]), np.array(group_estimation[\"med\"]))\n",
    "        high_mae, high_mse = get_eval(np.array(group_groundtruth[\"high\"]), np.array(group_estimation[\"high\"]))\n",
    "        \n",
    "        results_dict[\"test_mse_all\"] = test_mse\n",
    "        results_dict[\"test_mae_all\"] = test_mae\n",
    "        results_dict[\"test_mse_low\"] = low_mse\n",
    "        results_dict[\"test_mae_low\"] = low_mae\n",
    "        results_dict[\"test_mse_med\"] = med_mse\n",
    "        results_dict[\"test_mae_med\"] = med_mae\n",
    "        results_dict[\"test_mse_high\"] = high_mse\n",
    "        results_dict[\"test_mae_high\"] = high_mae\n",
    "        \n",
    "        print(results_dict)\n",
    "        if save:\n",
    "            plt.savefig(path + \"/\" + model_name + \".png\", dpi=300)\n",
    "            results_df = results_df.append(pd.DataFrame([results_dict]))\n",
    "            results_df.to_csv(path + \"/results.csv\", index=False)\n",
    "            print(\"Saved Results to \" + path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following lines, we load the entire Hetrec-MovieLens dataset and obtain two lists containing the user ids and the item ids respectively. Additionally, we conduct experiments on both, MetaMF and NoMetaMF under ten privacy budgets. The chosen hyperparameters are equal to those of Lin et. al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "beta_100p\n",
      "==========================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index out of range: Tried to access index 943 out of table with 942 rows. at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-e5c8dddg\\aten\\src\\TH/generic/THTensorEvenMoreMath.cpp:418",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7667a6601505>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_useranditemlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ThesisData/ml-100k/ml-100k/ml-100k\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_usergroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/User Groups/ml100k\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m run(\"experiments/meta/ml100k\", train, val, test, users, items, low, med, high, save=True, disable_meta_learning=False, \n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mbetas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     hyperparameters={\"lr\": 0.0001, \"lambda\": 0.001, \"batch_size\": 64, \"n_epochs\": 100})\n",
      "\u001b[1;32m<ipython-input-11-8f155e8d4ce9>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(path, traindata, valdata, testdata, userlist, itemlist, low, med, high, hyperparameters, betas, disable_meta_learning, save)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetbatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR_train_beta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Thesis B3\\RQ0\\RobustnessOfMetaMF-master\\RobustnessOfMetaMF-master\\MetaMF.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, user_id, item_id)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;31m#prediction module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mmodel_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_bias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_embedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetarecommender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[0mitem_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mitem_one_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Thesis B3\\RQ0\\RobustnessOfMetaMF-master\\RobustnessOfMetaMF-master\\MetaMF.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, user_id)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m#collaborative memory module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0muser_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mcf_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: index out of range: Tried to access index 943 out of table with 942 rows. at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-e5c8dddg\\aten\\src\\TH/generic/THTensorEvenMoreMath.cpp:418"
     ]
    }
   ],
   "source": [
    "train, val, test = read_dataset(\"ThesisData/ml-100k/ml-100k/ml-100k\")\n",
    "users, items = read_useranditemlist(\"ThesisData/ml-100k/ml-100k/ml-100k\")\n",
    "low, med, high = read_usergroups(\"data/User Groups/ml100k\")\n",
    "run(\"experiments/meta/ml100k\", train, val, test, users, items, low, med, high, save=True, disable_meta_learning=False, \n",
    "    betas=[1],\n",
    "    hyperparameters={\"lr\": 0.0001, \"lambda\": 0.001, \"batch_size\": 64, \"n_epochs\": 100})\n",
    "\n",
    "#run(\"experiments/nometa/ml100k\", train, val, test, users, items, low, med, high, save=True, disable_meta_learning=True, \n",
    "#    hyperparameters={\"lr\": 0.0001, \"lambda\": 0.001, \"batch_size\": 64, \"n_epochs\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
