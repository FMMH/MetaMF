{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlhundredk_train_df = pd.read_csv('ThesisData/ml-100k/ml-100k_time/ml-100k.train.rating', sep = ',', header=None, names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "mlhundredk_val_df = pd.read_csv('ThesisData/ml-100k/ml-100k_time/ml-100k.valid.rating', sep = ',', header=None, names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "mlhundredk_test_df = pd.read_csv('ThesisData/ml-100k/ml-100k_time/ml-100k.test.rating', sep = ',', header=None, names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "mlhundredk_df = mlhundredk_train_df.append(mlhundredk_val_df).append(mlhundredk_test_df)\n",
    "\n",
    "mlonem_train_df = pd.read_csv('ThesisData/ml-1m/ml-1m_time/ml-1m.train.rating', sep = ',', header=None, names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "mlonem_val_df = pd.read_csv('ThesisData/ml-1m/ml-1m_time/ml-1m.valid.rating', sep = ',', header=None, names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "mlonem_test_df = pd.read_csv('ThesisData/ml-1m/ml-1m_time/ml-1m.test.rating', sep = ',', header=None, names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "mlonem_df = mlonem_train_df.append(mlonem_val_df).append(mlonem_test_df)\n",
    "\n",
    "mllatsmall_train_df = pd.read_csv('ThesisData/ml-latest-small/ml-latest-small_time/ml-latest-small.train.rating', sep = ',', header=None, names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "mllatsmall_val_df = pd.read_csv('ThesisData/ml-latest-small/ml-latest-small_time/ml-latest-small.valid.rating', sep = ',', header=None, names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "mllatsmall_test_df = pd.read_csv('ThesisData/ml-latest-small/ml-latest-small_time/ml-latest-small.test.rating', sep = ',', header=None, names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "mllatsmall_df = mllatsmall_train_df.append(mllatsmall_val_df).append(mllatsmall_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify User Groups\n",
    "We identify three user groups: Users with the smallest amount of rating data ($Low$), users with most rating data ($High$) and users, whose amount of ratings is around the median ($Med$). These three user groups are constructed for five different datasets: Douban, Hetrec-MovieLens, MovieLens 1M, Ciao and Jester.\n",
    "## Douban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed low (125 users), med (125 users), high (125 users) usergroups.\n",
      "|U|: 375, |I|: 32191, |R|: 266517\n"
     ]
    }
   ],
   "source": [
    "user_popularity = db_df.groupby(\"user_id\").size().sort_values(ascending=True)\n",
    "n_5p_users = np.round(db_df[\"user_id\"].nunique() * 0.05).astype(int) #change to 0.10\n",
    "low_users = user_popularity[:n_5p_users].index.tolist()\n",
    "med_users = np.abs(user_popularity - user_popularity.median()).sort_values(ascending=True)[:n_5p_users].index.tolist()\n",
    "high_users = user_popularity[-n_5p_users:].index.tolist()\n",
    "print(\"Constructed low (%d users), med (%d users), high (%d users) usergroups.\" % (len(low_users), len(med_users), len(high_users)))\n",
    "\n",
    "pd.DataFrame(low_users).to_csv(\"data/User Groups/db_low.userlist\", header=None, index=False)\n",
    "pd.DataFrame(med_users).to_csv(\"data/User Groups/db_med.userlist\", header=None, index=False)\n",
    "pd.DataFrame(high_users).to_csv(\"data/User Groups/db_high.userlist\", header=None, index=False)\n",
    "\n",
    "df = db_df[db_df[\"user_id\"].isin(low_users)].append(db_df[db_df[\"user_id\"].isin(med_users)]).append(db_df[db_df[\"user_id\"].isin(high_users)])\n",
    "df.to_csv(\"data/User Groups/db_ratings.txt\", index=False)\n",
    "\n",
    "n_users = df[\"user_id\"].nunique()\n",
    "n_items = df[\"item_id\"].nunique()\n",
    "n_ratings = len(df)\n",
    "print(\"|U|: %d, |I|: %d, |R|: %d\" % (n_users, n_items, n_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hetrec-MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed low (106 users), med (106 users), high (106 users) usergroups.\n",
      "|U|: 318, |I|: 9553, |R|: 207943\n"
     ]
    }
   ],
   "source": [
    "user_popularity = html_df.groupby(\"user_id\").size().sort_values(ascending=True)\n",
    "n_5p_users = np.round(html_df[\"user_id\"].nunique() * 0.05).astype(int)\n",
    "low_users = user_popularity[:n_5p_users].index.tolist()\n",
    "med_users = np.abs(user_popularity - user_popularity.median()).sort_values(ascending=True)[:n_5p_users].index.tolist()\n",
    "high_users = user_popularity[-n_5p_users:].index.tolist()\n",
    "print(\"Constructed low (%d users), med (%d users), high (%d users) usergroups.\" % (len(low_users), len(med_users), len(high_users)))\n",
    "\n",
    "pd.DataFrame(low_users).to_csv(\"data/User Groups/ht-ml_low.userlist\", header=None, index=False)\n",
    "pd.DataFrame(med_users).to_csv(\"data/User Groups/ht-ml_med.userlist\", header=None, index=False)\n",
    "pd.DataFrame(high_users).to_csv(\"data/User Groups/ht-ml_high.userlist\", header=None, index=False)\n",
    "df = html_df[html_df[\"user_id\"].isin(low_users)].append(html_df[html_df[\"user_id\"].isin(med_users)]).append(html_df[html_df[\"user_id\"].isin(high_users)])\n",
    "df.to_csv(\"data/User Groups/ht-ml_ratings.txt\", index=False)\n",
    "\n",
    "n_users = df[\"user_id\"].nunique()\n",
    "n_items = df[\"item_id\"].nunique()\n",
    "n_ratings = len(df)\n",
    "print(\"|U|: %d, |I|: %d, |R|: %d\" % (n_users, n_items, n_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed low (302 users), med (302 users), high (302 users) usergroups.\n",
      "|U|: 906, |I|: 3613, |R|: 275119\n"
     ]
    }
   ],
   "source": [
    "user_popularity = ml_df.groupby(\"user_id\").size().sort_values(ascending=True)\n",
    "n_5p_users = np.round(ml_df[\"user_id\"].nunique() * 0.05).astype(int)\n",
    "low_users = user_popularity[:n_5p_users].index.tolist()\n",
    "med_users = np.abs(user_popularity - user_popularity.median()).sort_values(ascending=True)[:n_5p_users].index.tolist()\n",
    "high_users = user_popularity[-n_5p_users:].index.tolist()\n",
    "print(\"Constructed low (%d users), med (%d users), high (%d users) usergroups.\" % (len(low_users), len(med_users), len(high_users)))\n",
    "\n",
    "pd.DataFrame(low_users).to_csv(\"data/User Groups/ml_low.userlist\", header=None, index=False)\n",
    "pd.DataFrame(med_users).to_csv(\"data/User Groups/ml_med.userlist\", header=None, index=False)\n",
    "pd.DataFrame(high_users).to_csv(\"data/User Groups/ml_high.userlist\", header=None, index=False)\n",
    "df = ml_df[ml_df[\"user_id\"].isin(low_users)].append(ml_df[ml_df[\"user_id\"].isin(med_users)]).append(ml_df[ml_df[\"user_id\"].isin(high_users)])\n",
    "df.to_csv(\"data/User Groups/ml_ratings.txt\", index=False)\n",
    "\n",
    "n_users = df[\"user_id\"].nunique()\n",
    "n_items = df[\"item_id\"].nunique()\n",
    "n_ratings = len(df)\n",
    "print(\"|U|: %d, |I|: %d, |R|: %d\" % (n_users, n_items, n_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed low (369 users), med (369 users), high (369 users) usergroups.\n",
      "|U|: 1107, |I|: 60132, |R|: 107807\n"
     ]
    }
   ],
   "source": [
    "user_popularity = ciao_df.groupby(\"user_id\").size().sort_values(ascending=True)\n",
    "n_5p_users = np.round(ciao_df[\"user_id\"].nunique() * 0.05).astype(int)\n",
    "low_users = user_popularity[:n_5p_users].index.tolist()\n",
    "med_users = np.abs(user_popularity - user_popularity.median()).sort_values(ascending=True)[:n_5p_users].index.tolist()\n",
    "high_users = user_popularity[-n_5p_users:].index.tolist()\n",
    "print(\"Constructed low (%d users), med (%d users), high (%d users) usergroups.\" % (len(low_users), len(med_users), len(high_users)))\n",
    "\n",
    "pd.DataFrame(low_users).to_csv(\"data/User Groups/ciao_low.userlist\", header=None, index=False)\n",
    "pd.DataFrame(med_users).to_csv(\"data/User Groups/ciao_med.userlist\", header=None, index=False)\n",
    "pd.DataFrame(high_users).to_csv(\"data/User Groups/ciao_high.userlist\", header=None, index=False)\n",
    "df = ciao_df[ciao_df[\"user_id\"].isin(low_users)].append(ciao_df[ciao_df[\"user_id\"].isin(med_users)]).append(ciao_df[ciao_df[\"user_id\"].isin(high_users)])\n",
    "df.to_csv(\"data/User Groups/ciao_ratings.txt\", index=False)\n",
    "\n",
    "n_users = df[\"user_id\"].nunique()\n",
    "n_items = df[\"item_id\"].nunique()\n",
    "n_ratings = len(df)\n",
    "print(\"|U|: %d, |I|: %d, |R|: %d\" % (n_users, n_items, n_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jester_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-ce184918bb59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muser_popularity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjester_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user_id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mn_5p_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjester_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"user_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlow_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_popularity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_5p_users\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmed_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_popularity\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0muser_popularity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_5p_users\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhigh_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_popularity\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_5p_users\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jester_df' is not defined"
     ]
    }
   ],
   "source": [
    "user_popularity = jester_df.groupby(\"user_id\").size().sort_values(ascending=True)\n",
    "n_5p_users = np.round(jester_df[\"user_id\"].nunique() * 0.05).astype(int)\n",
    "low_users = user_popularity[:n_5p_users].index.tolist()\n",
    "med_users = np.abs(user_popularity - user_popularity.median()).sort_values(ascending=True)[:n_5p_users].index.tolist()\n",
    "high_users = user_popularity[-n_5p_users:].index.tolist()\n",
    "print(\"Constructed low (%d users), med (%d users), high (%d users) usergroups.\" % (len(low_users), len(med_users), len(high_users)))\n",
    "\n",
    "pd.DataFrame(low_users).to_csv(\"data/User Groups/jester_low.userlist\", header=None, index=False)\n",
    "pd.DataFrame(med_users).to_csv(\"data/User Groups/jester_med.userlist\", header=None, index=False)\n",
    "pd.DataFrame(high_users).to_csv(\"data/User Groups/jester_high.userlist\", header=None, index=False)\n",
    "df = jester_df[jester_df[\"user_id\"].isin(low_users)].append(jester_df[jester_df[\"user_id\"].isin(med_users)]).append(jester_df[jester_df[\"user_id\"].isin(high_users)])\n",
    "df.to_csv(\"data/User Groups/jester_ratings.txt\", index=False)\n",
    "\n",
    "n_users = df[\"user_id\"].nunique()\n",
    "n_items = df[\"item_id\"].nunique()\n",
    "n_ratings = len(df)\n",
    "print(\"|U|: %d, |I|: %d, |R|: %d\" % (n_users, n_items, n_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets used in the user profile minimization thesis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens 100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed low (141 users), med (141 users), high (141 users) usergroups.\n",
      "|U|: 423, |I|: 1658, |R|: 54525\n",
      "user_id\n",
      "380     20\n",
      "852     20\n",
      "642     20\n",
      "258     20\n",
      "629     20\n",
      "      ... \n",
      "37     518\n",
      "442    540\n",
      "58     636\n",
      "650    685\n",
      "402    737\n",
      "Length: 943, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "user_popularity = mlhundredk_df.groupby(\"user_id\").size().sort_values(ascending=True)\n",
    "n_5p_users = np.round(mlhundredk_df[\"user_id\"].nunique() * 0.15).astype(int)\n",
    "low_users = user_popularity[:n_5p_users].index.tolist()\n",
    "med_users = np.abs(user_popularity - user_popularity.median()).sort_values(ascending=True)[:n_5p_users].index.tolist()\n",
    "high_users = user_popularity[-n_5p_users:].index.tolist()\n",
    "print(\"Constructed low (%d users), med (%d users), high (%d users) usergroups.\" % (len(low_users), len(med_users), len(high_users)))\n",
    "\n",
    "pd.DataFrame(low_users).to_csv(\"data/User Groups/time/ml100k_low.userlist\", header=None, index=False)\n",
    "pd.DataFrame(med_users).to_csv(\"data/User Groups/time/ml100k_med.userlist\", header=None, index=False)\n",
    "pd.DataFrame(high_users).to_csv(\"data/User Groups/time/ml100k_high.userlist\", header=None, index=False)\n",
    "df = mlhundredk_df[mlhundredk_df[\"user_id\"].isin(low_users)].append(mlhundredk_df[mlhundredk_df[\"user_id\"].isin(med_users)]).append(mlhundredk_df[mlhundredk_df[\"user_id\"].isin(high_users)])\n",
    "df.to_csv(\"data/User Groups/ml100k_ratings.txt\", index=False)\n",
    "\n",
    "n_users = df[\"user_id\"].nunique()\n",
    "n_items = df[\"item_id\"].nunique()\n",
    "n_ratings = len(df)\n",
    "print(\"|U|: %d, |I|: %d, |R|: %d\" % (n_users, n_items, n_ratings))\n",
    "print(user_popularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed low (302 users), med (302 users), high (302 users) usergroups.\n",
      "|U|: 906, |I|: 3613, |R|: 275119\n"
     ]
    }
   ],
   "source": [
    "user_popularity = mlonem_df.groupby(\"user_id\").size().sort_values(ascending=True)\n",
    "n_5p_users = np.round(mlonem_df[\"user_id\"].nunique() * 0.05).astype(int)\n",
    "low_users = user_popularity[:n_5p_users].index.tolist()\n",
    "med_users = np.abs(user_popularity - user_popularity.median()).sort_values(ascending=True)[:n_5p_users].index.tolist()\n",
    "high_users = user_popularity[-n_5p_users:].index.tolist()\n",
    "print(\"Constructed low (%d users), med (%d users), high (%d users) usergroups.\" % (len(low_users), len(med_users), len(high_users)))\n",
    "\n",
    "pd.DataFrame(low_users).to_csv(\"data/User Groups/ml1m_low.userlist\", header=None, index=False)\n",
    "pd.DataFrame(med_users).to_csv(\"data/User Groups/ml1m_med.userlist\", header=None, index=False)\n",
    "pd.DataFrame(high_users).to_csv(\"data/User Groups/ml1m_high.userlist\", header=None, index=False)\n",
    "df = mlonem_df[mlonem_df[\"user_id\"].isin(low_users)].append(mlonem_df[mlonem_df[\"user_id\"].isin(med_users)]).append(mlonem_df[mlonem_df[\"user_id\"].isin(high_users)])\n",
    "df.to_csv(\"data/User Groups/ml1m_ratings.txt\", index=False)\n",
    "\n",
    "n_users = df[\"user_id\"].nunique()\n",
    "n_items = df[\"item_id\"].nunique()\n",
    "n_ratings = len(df)\n",
    "print(\"|U|: %d, |I|: %d, |R|: %d\" % (n_users, n_items, n_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens Latest Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed low (122 users), med (122 users), high (122 users) usergroups.\n",
      "|U|: 366, |I|: 9348, |R|: 77075\n"
     ]
    }
   ],
   "source": [
    "user_popularity = mllatsmall_df.groupby(\"user_id\").size().sort_values(ascending=True)\n",
    "n_5p_users = np.round(mllatsmall_df[\"user_id\"].nunique() * 0.20).astype(int)\n",
    "low_users = user_popularity[:n_5p_users].index.tolist()\n",
    "med_users = np.abs(user_popularity - user_popularity.median()).sort_values(ascending=True)[:n_5p_users].index.tolist()\n",
    "high_users = user_popularity[-n_5p_users:].index.tolist()\n",
    "print(\"Constructed low (%d users), med (%d users), high (%d users) usergroups.\" % (len(low_users), len(med_users), len(high_users)))\n",
    "\n",
    "pd.DataFrame(low_users).to_csv(\"data/User Groups/mlls_low.userlist\", header=None, index=False)\n",
    "pd.DataFrame(med_users).to_csv(\"data/User Groups/mlls_med.userlist\", header=None, index=False)\n",
    "pd.DataFrame(high_users).to_csv(\"data/User Groups/mlls_high.userlist\", header=None, index=False)\n",
    "df = mllatsmall_df[mllatsmall_df[\"user_id\"].isin(low_users)].append(mllatsmall_df[mllatsmall_df[\"user_id\"].isin(med_users)]).append(mllatsmall_df[mllatsmall_df[\"user_id\"].isin(high_users)])\n",
    "df.to_csv(\"data/User Groups/mlls_ratings.txt\", index=False)\n",
    "\n",
    "n_users = df[\"user_id\"].nunique()\n",
    "n_items = df[\"item_id\"].nunique()\n",
    "n_ratings = len(df)\n",
    "print(\"|U|: %d, |I|: %d, |R|: %d\" % (n_users, n_items, n_ratings))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
